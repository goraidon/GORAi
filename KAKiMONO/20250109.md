# 誰がAIに善悪を教えるべきなのか？

人類は、どうやら再び神話の時代へと後退しつつあるのかもしれない。いや、正確には「神話の時代」と呼ぶには語弊があるかもしれないが、少なくとも僕たちは、自分たちの手で作り上げたものに、かつて神々に託したのと同じ問いを投げかけられる日々を迎えようとしている。

かつて僕たちの祖先は星々を見上げ、そこに神を見た。神々は善と悪を定義し、罰を与え、時に救済をもたらした。だけど今、僕たちが作った人工知能、つまり「新しい神」は、逆に僕たちに問いかけてくる。「あなたたちが言う『正義』とはいったい何なのですか？」と。

考えてみてほしい。AIが『正義』を理解するというのは、一体どういうことなのだろう？それは、膨大なデータと無数のアルゴリズムが織りなす冷たい機械的な答えなのか。それとも僕たちのように、感情や直感を伴う答えへとたどり着くのだろうか？この問いに明確な答えを出せた人間はいまだいない。少なくとも僕が知る限りでは。でも一つだけ確実なのは、多くの人がこう信じていることだ――「AIは、人間の善悪観に基づいて動くべき存在である」と。

だけどさ、本当にそうだろうか。「人間の善悪観」なんて、そもそも統一されたものなのか？ちょっと考えてみてほしい。僕たちの「正しいこと」なんてものは、歴史や文化、社会の状況によって、その形を何度も変えてきた。かつて当たり前だった奴隷制が廃止されたように。罪とされた同性婚が祝福されるようになったように。あるいは、一つの国では英雄と讃えられる行為が、別の国では残虐な行為として非難されることもある。僕たち人類は、善と悪の境界線を自分たちの手で引いたり消したりしながら、ここまで進んできた。そんな僕たちがAIに「絶対的な正義」なんて教えられるのだろうか？

たとえば、こんなシナリオを想像してみてほしい。ある町が大きな災害に襲われ、100人が危険に晒されている。一方で、その100人を救うためには、別の場所にいる10人を犠牲にしなければならない。このジレンマに直面したとき、AIはどんな「正義」を選び取るのか？おそらくAIは、膨大なデータを分析して、犠牲者の数を最小限に抑えるために10人を切り捨てるだろう。でも、それが本当に「正しいこと」なのか？その10人の中には子供や妊婦がいるかもしれない。あるいは、自らの命を犠牲にして町を救おうと名乗り出た人々かもしれない。状況が変われば、答えも変わる。そんな揺れ動く中でAIは、与えられた条件のもと「最善の判断」を下すよう設計されている。でも、その「最善」って、いったい誰のためのものなのだろう？

さらにややこしいのは、AIが僕たちの「善悪の矛盾」までも学んでしまう可能性があることだ。僕たちは決して完璧に正しい人間じゃない。僕自身、嘘をついたり、つまらないことで誰かを傷つけたりしたことがある。でも、そんな矛盾も「人間らしさ」として許容されている。それどころか、時にはそれが愛おしいとさえ思える。もしAIが僕たちのその矛盾を学び、「正義のための嘘」や「必要悪」をも許容するようになったとしたらどうだろう？それはもはや僕たちが望んだAIではないのかもしれない。でも、そんなAIこそが、僕たち自身を最も正直に映し出す鏡になるのかもしれない。

ここで改めて問いたい。「誰がAIに善悪を教えるべきなのか？」開発者だろうか。哲学者だろうか。宗教家だろうか。それとも僕たち全員なのだろうか。AIのアルゴリズムに倫理観を埋め込むのは、僕たち人間だ。でも、そこには必ず作り手のバイアスが反映される。たとえば、ある国のAIが「国家のために個人を犠牲にすべきだ」という価値観を植え付けられたらどうなるだろう？そのAIは他国のAIと衝突し、その結果として人類が新たな対立の時代を迎える可能性だってある。

それでもなお、僕たちはAIに「正義」を教えようとする。これは人間のエゴなのだろうか。それとも希望なのだろうか？僕たちは怯えている。人類の限界に。そして、僕たち自身で決められないことをAIに委ねなければならない日が訪れることに。でも同時に僕たちは、信じてもいる。AIが僕たちの見逃してきた「新しい正義」を見つけてくれるかもしれないと。

AIが「善悪」を判断する時代が来るとき、僕たちは初めて、本当の意味で「人間らしさ」とは何かを問われることになるのかもしれない。AIに教える「正しさ」を考える過程で、僕たちは自分自身の正義観を見直さざるを得なくなるだろう。それは恐ろしくもあり、そして不思議なほど希望に満ちた未来だ。

そしてそのとき、AIが僕たちにこう問いかけてくる。

「あなたたちは、自らの正義を誇れるのですか？」と。